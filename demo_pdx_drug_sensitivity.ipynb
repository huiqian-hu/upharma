{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDX Drug Sensitivity Prediction - Demonstration\n",
    "\n",
    "## Based on: μPharma - A Microfluidic AI-driven Pharmacotyping Platform\n",
    "\n",
    "This demo notebook demonstrates our PDX-specific drug sensitivity prediction methodology using synthetic data that mimics the structure of real T-ALL PDX models.\n",
    "\n",
    "**Key Features:**\n",
    "- Drug-specific feature engineering (LCK for Dasatinib, BCL2 for Venetoclax)\n",
    "- PDX-aware rotational cross-validation\n",
    "- XGBoost with drug-specific hyperparameters\n",
    "- SHAP-based interpretability\n",
    "- UMAP visualization from SHAP values\n",
    "\n",
    "**Authors:** Huiqian Hu, Alphonsus H. C. Ng, Yue Lu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    'numpy', 'pandas', 'scikit-learn', 'xgboost', \n",
    "    'matplotlib', 'seaborn', 'shap', 'umap-learn', 'imbalanced-learn'\n",
    "]\n",
    "\n",
    "# Check and install missing packages\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        install(package)\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, confusion_matrix, \n",
    "    accuracy_score, f1_score, precision_score, recall_score\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import shap\n",
    "import umap\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "print(f\"XGBoost version: {xgboost.__version__}\")\n",
    "print(f\"SHAP version: {shap.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic PDX Data\n",
    "\n",
    "We create synthetic data that mimics the structure of real PDX experiments with 14 PDX groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_pdx_data(n_samples_per_group=150, random_state=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic PDX data mimicking real experimental structure.\n",
    "    \n",
    "    Creates data for 14 PDX groups with morphological and protein expression features.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Define 14 PDX groups (matching manuscript)\n",
    "    pdx_groups = ['SJ65', 'SJ49', 'SJ53', 'SJ52', 'SJ7', \n",
    "                  '1054', '145', '741', '748', '758', \n",
    "                  '2176', '4404', '4406', '4426']\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for group_idx, group_name in enumerate(pdx_groups):\n",
    "        # Each PDX group has slightly different characteristics\n",
    "        group_offset = group_idx * 0.1\n",
    "        \n",
    "        for _ in range(n_samples_per_group):\n",
    "            # Morphological features (AreaShape)\n",
    "            area = np.random.normal(100 + group_offset*10, 15)\n",
    "            perimeter = np.random.normal(40 + group_offset*5, 5)\n",
    "            form_factor = np.random.uniform(0.5, 0.9)\n",
    "            eccentricity = np.random.uniform(0.3, 0.8)\n",
    "            solidity = np.random.uniform(0.7, 1.0)\n",
    "            extent = np.random.uniform(0.5, 0.85)\n",
    "            \n",
    "            # Protein expression features\n",
    "            # LCK pathway (relevant for Dasatinib)\n",
    "            lck_base = np.random.lognormal(3.0 + group_offset, 0.5)\n",
    "            plck_ratio = np.random.beta(2, 5)  # Phosphorylation ratio\n",
    "            \n",
    "            intensity_mean_lck = lck_base\n",
    "            intensity_mean_plck = lck_base * plck_ratio\n",
    "            intensity_lower_plck = intensity_mean_plck * np.random.uniform(0.7, 0.9)\n",
    "            intensity_upper_plck = intensity_mean_plck * np.random.uniform(1.1, 1.3)\n",
    "            \n",
    "            # BCL2 pathway (relevant for Venetoclax)\n",
    "            bcl2_base = np.random.lognormal(2.8 + group_offset*0.8, 0.4)\n",
    "            pbcl2_ratio = np.random.beta(3, 4)\n",
    "            \n",
    "            intensity_mean_bcl2 = bcl2_base\n",
    "            intensity_mean_pbcl2 = bcl2_base * pbcl2_ratio\n",
    "            intensity_upper_pbcl2 = intensity_mean_pbcl2 * np.random.uniform(1.05, 1.25)\n",
    "            intensity_min_edge_bcl2 = intensity_mean_bcl2 * np.random.uniform(0.5, 0.8)\n",
    "            \n",
    "            # Drug sensitivity (binary outcome)\n",
    "            # Dasatinib sensitivity correlates with pLCK/LCK ratio\n",
    "            dasatinib_score = plck_ratio + eccentricity*0.3 + np.random.normal(0, 0.2)\n",
    "            dasatinib_sensitive = int(dasatinib_score > 0.5)\n",
    "            \n",
    "            # Venetoclax sensitivity correlates with pBCL2/BCL2 ratio\n",
    "            venetoclax_score = pbcl2_ratio + solidity*0.2 + np.random.normal(0, 0.2)\n",
    "            venetoclax_sensitive = int(venetoclax_score > 0.55)\n",
    "            \n",
    "            sample = {\n",
    "                'Group': group_name,\n",
    "                'Sample_Type': 'PDX',\n",
    "                \n",
    "                # Morphological features\n",
    "                'AreaShape_Area': area,\n",
    "                'AreaShape_Perimeter': perimeter,\n",
    "                'AreaShape_FormFactor': form_factor,\n",
    "                'AreaShape_Eccentricity': eccentricity,\n",
    "                'AreaShape_Solidity': solidity,\n",
    "                'AreaShape_Extent': extent,\n",
    "                \n",
    "                # LCK features\n",
    "                'Intensity_MeanIntensity_LCK': intensity_mean_lck,\n",
    "                'Intensity_MeanIntensity_pLCK': intensity_mean_plck,\n",
    "                'Intensity_LowerQuartileIntensity_pLCK': intensity_lower_plck,\n",
    "                'Intensity_UpperQuartileIntensity_pLCK': intensity_upper_plck,\n",
    "                \n",
    "                # BCL2 features\n",
    "                'Intensity_MeanIntensity_BCL_2': intensity_mean_bcl2,\n",
    "                'Intensity_MeanIntensity_pBCL2': intensity_mean_pbcl2,\n",
    "                'Intensity_UpperQuartileIntensity_pBCL2': intensity_upper_pbcl2,\n",
    "                'Intensity_MinIntensityEdge_BCL_2': intensity_min_edge_bcl2,\n",
    "                \n",
    "                # Drug sensitivities\n",
    "                'Dasatinib Sensitivity': dasatinib_sensitive,\n",
    "                'Venetoclax Sensitivity': venetoclax_sensitive\n",
    "            }\n",
    "            \n",
    "            all_data.append(sample)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# Generate data\n",
    "print(\"Generating synthetic PDX data...\")\n",
    "pdx_df = generate_synthetic_pdx_data(n_samples_per_group=150)\n",
    "\n",
    "print(f\"\\n✅ Generated dataset with {len(pdx_df)} samples\")\n",
    "print(f\"Number of PDX groups: {pdx_df['Group'].nunique()}\")\n",
    "print(f\"\\nPDX groups: {', '.join(pdx_df['Group'].unique())}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"Dasatinib - Sensitive: {pdx_df['Dasatinib Sensitivity'].sum()}, Resistant: {len(pdx_df) - pdx_df['Dasatinib Sensitivity'].sum()}\")\n",
    "print(f\"Venetoclax - Sensitive: {pdx_df['Venetoclax Sensitivity'].sum()}, Resistant: {len(pdx_df) - pdx_df['Venetoclax Sensitivity'].sum()}\")\n",
    "\n",
    "# Display first few rows\n",
    "pdx_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Create drug-specific engineered features including ratios, log transformations, and interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Engineer features following the manuscript methodology.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Basic ratio features\n",
    "    df['pLCK_to_LCK_ratio'] = np.divide(\n",
    "        df['Intensity_MeanIntensity_pLCK'].values,\n",
    "        df['Intensity_MeanIntensity_LCK'].values,\n",
    "        out=np.zeros_like(df['Intensity_MeanIntensity_pLCK'].values, dtype=float),\n",
    "        where=df['Intensity_MeanIntensity_LCK'].values!=0\n",
    "    )\n",
    "    \n",
    "    df['pBCL2_to_BCL2_ratio'] = np.divide(\n",
    "        df['Intensity_MeanIntensity_pBCL2'].values,\n",
    "        df['Intensity_MeanIntensity_BCL_2'].values,\n",
    "        out=np.zeros_like(df['Intensity_MeanIntensity_pBCL2'].values, dtype=float),\n",
    "        where=df['Intensity_MeanIntensity_BCL_2'].values!=0\n",
    "    )\n",
    "    \n",
    "    # Log transformations\n",
    "    df['log_pLCK'] = np.log1p(df['Intensity_MeanIntensity_pLCK'])\n",
    "    df['log_LCK'] = np.log1p(df['Intensity_MeanIntensity_LCK'])\n",
    "    df['log_pBCL2'] = np.log1p(df['Intensity_MeanIntensity_pBCL2'])\n",
    "    df['log_BCL2'] = np.log1p(df['Intensity_MeanIntensity_BCL_2'])\n",
    "    \n",
    "    # Log ratios\n",
    "    df['log_pLCK_to_LCK_ratio'] = df['log_pLCK'] - df['log_LCK']\n",
    "    df['log_pBCL2_to_BCL2_ratio'] = df['log_pBCL2'] - df['log_BCL2']\n",
    "    \n",
    "    # Interaction features with morphology\n",
    "    df['pLCK_x_AreaShape_Area'] = df['Intensity_MeanIntensity_pLCK'] * df['AreaShape_Area']\n",
    "    df['pBCL2_x_AreaShape_Area'] = df['Intensity_MeanIntensity_pBCL2'] * df['AreaShape_Area']\n",
    "    \n",
    "    # Z-scores within PDX groups\n",
    "    for group in df['Group'].unique():\n",
    "        group_mask = df['Group'] == group\n",
    "        if sum(group_mask) > 1:\n",
    "            group_data = df.loc[group_mask, 'Intensity_MeanIntensity_pLCK']\n",
    "            df.loc[group_mask, 'pLCK_zscore'] = (group_data - group_data.mean()) / (group_data.std() + 1e-6)\n",
    "            \n",
    "            group_data = df.loc[group_mask, 'Intensity_MeanIntensity_pBCL2']\n",
    "            df.loc[group_mask, 'pBCL2_zscore'] = (group_data - group_data.mean()) / (group_data.std() + 1e-6)\n",
    "    \n",
    "    # Fill any missing z-scores\n",
    "    df['pLCK_zscore'] = df['pLCK_zscore'].fillna(0)\n",
    "    df['pBCL2_zscore'] = df['pBCL2_zscore'].fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "print(\"Applying feature engineering...\")\n",
    "pdx_df = engineer_features(pdx_df)\n",
    "\n",
    "# Define drug-specific feature sets\n",
    "lck_features = [col for col in pdx_df.columns if 'LCK' in col.upper() and 'BCL' not in col.upper()]\n",
    "bcl2_features = [col for col in pdx_df.columns if ('BCL' in col.upper() or 'pBCL2' in col) and 'LCK' not in col.upper()]\n",
    "shape_features = [col for col in pdx_df.columns if 'AreaShape' in col]\n",
    "\n",
    "dasatinib_features = list(set(lck_features + shape_features))\n",
    "venetoclax_features = list(set(bcl2_features + shape_features))\n",
    "\n",
    "print(f\"\\n✅ Feature engineering completed!\")\n",
    "print(f\"Dasatinib features: {len(dasatinib_features)}\")\n",
    "print(f\"Venetoclax features: {len(venetoclax_features)}\")\n",
    "print(f\"\\nSample engineered features:\")\n",
    "print(f\"  - pLCK/LCK ratio: {pdx_df['pLCK_to_LCK_ratio'].mean():.3f} ± {pdx_df['pLCK_to_LCK_ratio'].std():.3f}\")\n",
    "print(f\"  - pBCL2/BCL2 ratio: {pdx_df['pBCL2_to_BCL2_ratio'].mean():.3f} ± {pdx_df['pBCL2_to_BCL2_ratio'].std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define PDX Rotations\n",
    "\n",
    "We use predefined PDX rotations that ensure balanced training/validation/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dasatinib rotations (from manuscript)\n",
    "dasatinib_rotations = [\n",
    "    {\n",
    "        'train': np.array(['SJ65', 'SJ49', 'SJ53', 'SJ52', '1054', '145', '741', '748', '4406']),\n",
    "        'val': np.array(['SJ7', '4426']),\n",
    "        'test': np.array(['758', '2176', '4404'])\n",
    "    },\n",
    "    {\n",
    "        'train': np.array(['SJ65', 'SJ49', 'SJ52', '4426', '4404', '4406', '741', '758', '2176']),\n",
    "        'val': np.array(['145', '748']),\n",
    "        'test': np.array(['SJ7', 'SJ53', '1054'])\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define Venetoclax rotations (from manuscript)\n",
    "venetoclax_rotations = [\n",
    "    {\n",
    "        'train': np.array(['SJ65', 'SJ7', '741', '4404', '748', 'SJ52', '1054', '4406', 'SJ49']),\n",
    "        'val': np.array(['4426', 'SJ53']),\n",
    "        'test': np.array(['2176', '758', '145'])\n",
    "    },\n",
    "    {\n",
    "        'train': np.array(['SJ65', 'SJ7', 'SJ49', '4406', '4404', '741', '758', '2176', '145']),\n",
    "        'val': np.array(['1054', '4426']),\n",
    "        'test': np.array(['748', 'SJ52', 'SJ53'])\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"PDX Rotation Setup:\")\n",
    "print(f\"\\nDasatinib - Rotation 1:\")\n",
    "print(f\"  Training: {', '.join(dasatinib_rotations[0]['train'])}\")\n",
    "print(f\"  Validation: {', '.join(dasatinib_rotations[0]['val'])}\")\n",
    "print(f\"  Testing: {', '.join(dasatinib_rotations[0]['test'])}\")\n",
    "\n",
    "print(f\"\\nVenetoclax - Rotation 1:\")\n",
    "print(f\"  Training: {', '.join(venetoclax_rotations[0]['train'])}\")\n",
    "print(f\"  Validation: {', '.join(venetoclax_rotations[0]['val'])}\")\n",
    "print(f\"  Testing: {', '.join(venetoclax_rotations[0]['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_xgboost(X_train, y_train, X_val, y_val, X_test, y_test, \n",
    "                               feature_names, drug_name=\"\", k_best=30, xgb_params=None):\n",
    "    \"\"\"\n",
    "    Train XGBoost model with feature selection and evaluation.\n",
    "    \"\"\"\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Handle class imbalance with SMOTE if needed\n",
    "    if pd.Series(y_train).value_counts().min() / pd.Series(y_train).value_counts().max() < 0.5:\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_scaled, y_train = smote.fit_resample(X_train_scaled, y_train)\n",
    "    \n",
    "    # Feature selection\n",
    "    selector = SelectKBest(f_classif, k=min(k_best, X_train.shape[1]))\n",
    "    X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "    X_val_selected = selector.transform(X_val_scaled)\n",
    "    X_test_selected = selector.transform(X_test_scaled)\n",
    "    \n",
    "    # Get selected feature names\n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "    selected_features = [feature_names[i] for i in selected_indices]\n",
    "    \n",
    "    # Define XGBoost model\n",
    "    if xgb_params is None:\n",
    "        xgb_params = {\n",
    "            'n_estimators': 100,\n",
    "            'learning_rate': 0.05,\n",
    "            'max_depth': 5,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8\n",
    "        }\n",
    "    \n",
    "    model = XGBClassifier(\n",
    "        **xgb_params,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(\n",
    "        X_train_selected, y_train,\n",
    "        eval_set=[(X_val_selected, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    y_pred_proba = model.predict_proba(X_test_selected)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
    "        'f1_score': f1_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'selector': selector,\n",
    "        'selected_features': selected_features,\n",
    "        'metrics': metrics,\n",
    "        'y_test': y_test,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'X_test_selected': X_test_selected\n",
    "    }\n",
    "\n",
    "print(\"✅ Model training function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Cross-Validation for Both Drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define drug-specific hyperparameters\n",
    "dasatinib_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 3,\n",
    "    'gamma': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "venetoclax_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 3,\n",
    "    'gamma': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "# Prepare data\n",
    "X_das = pdx_df[dasatinib_features]\n",
    "y_das = pdx_df['Dasatinib Sensitivity']\n",
    "\n",
    "X_ven = pdx_df[venetoclax_features]\n",
    "y_ven = pdx_df['Venetoclax Sensitivity']\n",
    "\n",
    "# Store results\n",
    "cv_results = {'dasatinib': [], 'venetoclax': []}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DASATINIB CROSS-VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for rot_idx, rotation in enumerate(dasatinib_rotations):\n",
    "    print(f\"\\nRotation {rot_idx+1}:\")\n",
    "    \n",
    "    # Get indices\n",
    "    train_idx = pdx_df[pdx_df['Group'].isin(rotation['train'])].index\n",
    "    val_idx = pdx_df[pdx_df['Group'].isin(rotation['val'])].index\n",
    "    test_idx = pdx_df[pdx_df['Group'].isin(rotation['test'])].index\n",
    "    \n",
    "    # Train and evaluate\n",
    "    result = train_and_evaluate_xgboost(\n",
    "        X_das.loc[train_idx], y_das.loc[train_idx],\n",
    "        X_das.loc[val_idx], y_das.loc[val_idx],\n",
    "        X_das.loc[test_idx], y_das.loc[test_idx],\n",
    "        dasatinib_features,\n",
    "        drug_name=\"Dasatinib\",\n",
    "        k_best=20,\n",
    "        xgb_params=dasatinib_params\n",
    "    )\n",
    "    \n",
    "    cv_results['dasatinib'].append(result)\n",
    "    \n",
    "    print(f\"  Accuracy: {result['metrics']['accuracy']:.3f}\")\n",
    "    print(f\"  ROC AUC: {result['metrics']['roc_auc']:.3f}\")\n",
    "    print(f\"  F1 Score: {result['metrics']['f1_score']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VENETOCLAX CROSS-VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for rot_idx, rotation in enumerate(venetoclax_rotations):\n",
    "    print(f\"\\nRotation {rot_idx+1}:\")\n",
    "    \n",
    "    # Get indices\n",
    "    train_idx = pdx_df[pdx_df['Group'].isin(rotation['train'])].index\n",
    "    val_idx = pdx_df[pdx_df['Group'].isin(rotation['val'])].index\n",
    "    test_idx = pdx_df[pdx_df['Group'].isin(rotation['test'])].index\n",
    "    \n",
    "    # Train and evaluate\n",
    "    result = train_and_evaluate_xgboost(\n",
    "        X_ven.loc[train_idx], y_ven.loc[train_idx],\n",
    "        X_ven.loc[val_idx], y_ven.loc[val_idx],\n",
    "        X_ven.loc[test_idx], y_ven.loc[test_idx],\n",
    "        venetoclax_features,\n",
    "        drug_name=\"Venetoclax\",\n",
    "        k_best=20,\n",
    "        xgb_params=venetoclax_params\n",
    "    )\n",
    "    \n",
    "    cv_results['venetoclax'].append(result)\n",
    "    \n",
    "    print(f\"  Accuracy: {result['metrics']['accuracy']:.3f}\")\n",
    "    print(f\"  ROC AUC: {result['metrics']['roc_auc']:.3f}\")\n",
    "    print(f\"  F1 Score: {result['metrics']['f1_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization: Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for best rotation of each drug\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Best Dasatinib rotation (highest AUC)\n",
    "best_das_idx = np.argmax([r['metrics']['roc_auc'] for r in cv_results['dasatinib']])\n",
    "best_das = cv_results['dasatinib'][best_das_idx]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(best_das['y_test'], best_das['y_pred_proba'])\n",
    "axes[0].plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label=f'ROC curve (AUC = {best_das[\"metrics\"][\"roc_auc\"]:.3f})')\n",
    "axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[0].set_xlim([0.0, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('Dasatinib - Best Rotation ROC Curve')\n",
    "axes[0].legend(loc=\"lower right\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Best Venetoclax rotation\n",
    "best_ven_idx = np.argmax([r['metrics']['roc_auc'] for r in cv_results['venetoclax']])\n",
    "best_ven = cv_results['venetoclax'][best_ven_idx]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(best_ven['y_test'], best_ven['y_pred_proba'])\n",
    "axes[1].plot(fpr, tpr, color='darkgreen', lw=2,\n",
    "             label=f'ROC curve (AUC = {best_ven[\"metrics\"][\"roc_auc\"]:.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('Venetoclax - Best Rotation ROC Curve')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best Dasatinib Rotation: {best_das_idx+1} (AUC: {best_das['metrics']['roc_auc']:.3f})\")\n",
    "print(f\"Best Venetoclax Rotation: {best_ven_idx+1} (AUC: {best_ven['metrics']['roc_auc']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. SHAP Analysis for Model Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis for best models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Dasatinib SHAP\n",
    "explainer_das = shap.TreeExplainer(best_das['model'])\n",
    "shap_values_das = explainer_das.shap_values(best_das['X_test_selected'])\n",
    "\n",
    "# Feature importance bar plot\n",
    "plt.sca(axes[0, 0])\n",
    "shap.summary_plot(shap_values_das, best_das['X_test_selected'],\n",
    "                   feature_names=best_das['selected_features'],\n",
    "                   plot_type=\"bar\", show=False, max_display=10)\n",
    "axes[0, 0].set_title('Dasatinib - SHAP Feature Importance')\n",
    "\n",
    "# Summary plot\n",
    "plt.sca(axes[0, 1])\n",
    "shap.summary_plot(shap_values_das, best_das['X_test_selected'],\n",
    "                   feature_names=best_das['selected_features'],\n",
    "                   show=False, max_display=10)\n",
    "axes[0, 1].set_title('Dasatinib - SHAP Summary')\n",
    "\n",
    "# Venetoclax SHAP\n",
    "explainer_ven = shap.TreeExplainer(best_ven['model'])\n",
    "shap_values_ven = explainer_ven.shap_values(best_ven['X_test_selected'])\n",
    "\n",
    "# Feature importance bar plot\n",
    "plt.sca(axes[1, 0])\n",
    "shap.summary_plot(shap_values_ven, best_ven['X_test_selected'],\n",
    "                   feature_names=best_ven['selected_features'],\n",
    "                   plot_type=\"bar\", show=False, max_display=10)\n",
    "axes[1, 0].set_title('Venetoclax - SHAP Feature Importance')\n",
    "\n",
    "# Summary plot\n",
    "plt.sca(axes[1, 1])\n",
    "shap.summary_plot(shap_values_ven, best_ven['X_test_selected'],\n",
    "                   feature_names=best_ven['selected_features'],\n",
    "                   show=False, max_display=10)\n",
    "axes[1, 1].set_title('Venetoclax - SHAP Summary')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Features by SHAP Importance:\")\n",
    "print(\"\\nDasatinib:\")\n",
    "shap_importance_das = np.abs(shap_values_das).mean(0)\n",
    "for i in np.argsort(shap_importance_das)[-5:][::-1]:\n",
    "    print(f\"  {best_das['selected_features'][i]}: {shap_importance_das[i]:.3f}\")\n",
    "\n",
    "print(\"\\nVenetoclax:\")\n",
    "shap_importance_ven = np.abs(shap_values_ven).mean(0)\n",
    "for i in np.argsort(shap_importance_ven)[-5:][::-1]:\n",
    "    print(f\"  {best_ven['selected_features'][i]}: {shap_importance_ven[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. UMAP Visualization from SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UMAP embeddings from SHAP values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Dasatinib UMAP\n",
    "reducer = umap.UMAP(random_state=42, n_neighbors=15)\n",
    "embedding_das = reducer.fit_transform(shap_values_das)\n",
    "\n",
    "# Get test PDX groups for coloring\n",
    "test_groups_das = pdx_df.loc[pdx_df['Group'].isin(dasatinib_rotations[best_das_idx]['test']), 'Group']\n",
    "test_idx_das = pdx_df[pdx_df['Group'].isin(dasatinib_rotations[best_das_idx]['test'])].index\n",
    "groups_for_plot = pdx_df.loc[test_idx_das, 'Group'].values\n",
    "\n",
    "# Plot colored by sensitivity\n",
    "scatter = axes[0].scatter(embedding_das[:, 0], embedding_das[:, 1],\n",
    "                         c=best_das['y_test'], cmap='coolwarm',\n",
    "                         s=100, alpha=0.7)\n",
    "axes[0].set_xlabel('UMAP 1')\n",
    "axes[0].set_ylabel('UMAP 2')\n",
    "axes[0].set_title('Dasatinib - UMAP from SHAP Values')\n",
    "plt.colorbar(scatter, ax=axes[0], label='Sensitivity')\n",
    "\n",
    "# Venetoclax UMAP\n",
    "embedding_ven = reducer.fit_transform(shap_values_ven)\n",
    "\n",
    "scatter = axes[1].scatter(embedding_ven[:, 0], embedding_ven[:, 1],\n",
    "                         c=best_ven['y_test'], cmap='coolwarm',\n",
    "                         s=100, alpha=0.7)\n",
    "axes[1].set_xlabel('UMAP 1')\n",
    "axes[1].set_ylabel('UMAP 2')\n",
    "axes[1].set_title('Venetoclax - UMAP from SHAP Values')\n",
    "plt.colorbar(scatter, ax=axes[1], label='Sensitivity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ UMAP visualization from SHAP values completed!\")\n",
    "print(\"\\nThe UMAP embeddings show how samples cluster based on their SHAP feature contributions,\")\n",
    "print(\"providing insights into the decision boundaries learned by the models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average metrics across rotations\n",
    "das_metrics = pd.DataFrame([r['metrics'] for r in cv_results['dasatinib']])\n",
    "ven_metrics = pd.DataFrame([r['metrics'] for r in cv_results['venetoclax']])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CROSS-VALIDATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nDasatinib Performance (Mean ± Std):\")\n",
    "for metric in das_metrics.columns:\n",
    "    print(f\"  {metric}: {das_metrics[metric].mean():.3f} ± {das_metrics[metric].std():.3f}\")\n",
    "\n",
    "print(\"\\nVenetoclax Performance (Mean ± Std):\")\n",
    "for metric in ven_metrics.columns:\n",
    "    print(f\"  {metric}: {ven_metrics[metric].mean():.3f} ± {ven_metrics[metric].std():.3f}\")\n",
    "\n",
    "# Feature consistency analysis\n",
    "das_features_all = [r['selected_features'] for r in cv_results['dasatinib']]\n",
    "ven_features_all = [r['selected_features'] for r in cv_results['venetoclax']]\n",
    "\n",
    "# Count feature frequency\n",
    "from collections import Counter\n",
    "das_feature_counts = Counter([f for features in das_features_all for f in features])\n",
    "ven_feature_counts = Counter([f for features in ven_features_all for f in features])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE CONSISTENCY ACROSS ROTATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nMost Consistent Dasatinib Features:\")\n",
    "for feature, count in das_feature_counts.most_common(5):\n",
    "    print(f\"  {feature}: selected in {count}/{len(dasatinib_rotations)} rotations\")\n",
    "\n",
    "print(\"\\nMost Consistent Venetoclax Features:\")\n",
    "for feature, count in ven_feature_counts.most_common(5):\n",
    "    print(f\"  {feature}: selected in {count}/{len(venetoclax_rotations)} rotations\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. Drug-Specific Feature Selection:\n",
    "   - Dasatinib models rely primarily on LCK-related features\n",
    "   - Venetoclax models rely primarily on BCL2-related features\n",
    "   - Both drugs utilize morphological features (AreaShape)\n",
    "\n",
    "2. PDX Rotation Importance:\n",
    "   - Model performance varies with different PDX group assignments\n",
    "   - Optimal rotations are drug-specific\n",
    "   - Cross-validation ensures robust performance estimates\n",
    "\n",
    "3. Model Interpretability:\n",
    "   - SHAP analysis reveals feature importance and interactions\n",
    "   - UMAP visualization shows clear separation of sensitive/resistant samples\n",
    "   - Top features align with known drug mechanisms of action\n",
    "\n",
    "This demonstration validates our PDX-specific approach to drug sensitivity prediction.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}